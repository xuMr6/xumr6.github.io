<!DOCTYPE html>
<html>
<meta  lang="en" >
<head>
  <meta charset="UTF-8">
  <meta name="viewport"
    content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color" content="#fff" id="theme-color">
  <link rel="icon" href="/img/1.jpg">
  <title>Mr xu</title>
  
  
  <meta property="og:title" content="Scrapy框架（2）">
  
  
  <meta property="og:url" content="https://github.com/xuMr6/xumr6.github.io.git/2019/06/22/Scrapy%E6%A1%86%E6%9E%B6%EF%BC%882%EF%BC%89/index.html">
  
  
  <meta property="og:img" content="/img/1.jpg">
  
  
  
  <meta property="og:type" content="article">
  <meta property="og:article:published_time" content="2019-06-22">
  <meta property="og:article:modified_time" content="2020-09-04">
  <meta property="og:article:author" content="Mr xu">
  
  
  <meta property="og:article:tag" content="python">
  
  
  
  
  <script>
    // control reverse button
    var reverseDarkList = {
      dark: 'light',
      light: 'dark'
    };
    var themeColor = {
      dark: '#1c1c1e',
      light: '#fff'
    }
    // get the data of css prefers-color-scheme
    var getCssMediaQuery = function() {
      return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
    };
    // reverse current darkmode setting function
    var reverseDarkModeSetting = function() {
      var setting = localStorage.getItem('user-color-scheme');
      if(reverseDarkList[setting]) {
        setting = reverseDarkList[setting];
      } else if(setting === null) {
        setting = reverseDarkList[getCssMediaQuery()];
      } else {
        return;
      }
      localStorage.setItem('user-color-scheme', setting);
      return setting;
    };
    // apply current darkmode setting
    var setDarkmode = function(mode) {
      var setting = mode || localStorage.getItem('user-color-scheme');
      if(setting === getCssMediaQuery()) {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[setting];
      } else if(reverseDarkList[setting]) {
        document.documentElement.setAttribute('data-user-color-scheme', setting);
        document.getElementById('theme-color').content = themeColor[setting];
      } else {
        document.documentElement.removeAttribute('data-user-color-scheme');
        localStorage.removeItem('user-color-scheme');
        document.getElementById('theme-color').content = themeColor[getCssMediaQuery()];
      }
    };
    setDarkmode();
  </script>
  <script>
    function loadScript(url, cb) {
      var script = document.createElement('script');
      script.src = url;
      if (cb) script.onload = cb;
      script.async = true;
      document.body.appendChild(script);
    }
  </script>
  
  <link rel="preload" href="//at.alicdn.com/t/font_1946621_f7g5jnuftcf.css" as="style" >
  <link rel="preload" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css" as="style" >
  
  <link rel="preload" href="//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js" as="script">
  
  
  <link rel="preload" href="/js/lib/lozad.min.js" as="script">
  
  
  
  
  
  
  
  
<link rel="stylesheet" href="/css/main.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1946621_f7g5jnuftcf.css">

  
  
<link rel="stylesheet" href="//at.alicdn.com/t/font_1952792_89b4ac4k4up.css">

  
  
  
<meta name="generator" content="Hexo 5.1.1"><link rel="alternate" href="/atom.xml" title="XuMr" type="application/atom+xml">
</head>


<body>
  <div class="wrapper">
    
    <nav class="navbar">
  <div class="navbar-logo">
    <span class="navbar-logo-main">
      
      <img class="navbar-logo-img" src="/img/1.jpg">
      
      <span class="navbar-logo-dsc">Mr xu</span>
    </span>
  </div>
  <div class="navbar-menu">
    
    <a href="/" class="navbar-menu-item">
    
    首页
    
    </a>
    
    <a href="/archives" class="navbar-menu-item">
    
    时间
    
    </a>
    
    <a href="/tags" class="navbar-menu-item">
    
    标签
    
    </a>
    
    <a href="/categories" class="navbar-menu-item">
    
    分类
    
    </a>
    
    <a class="navbar-menu-item darknavbar" id="dark"><i class="iconfont icon-weather"></i></a>
    <a class="navbar-menu-item searchnavbar" id="search"><i class="iconfont icon-search" style="font-size: 1.2rem; font-weight: 400;"></i></a>
  </div>
</nav>
    
    <div id="local-search" style="display: none;">
      <input class="navbar-menu-item" id="search-input" placeholder="请输入搜索内容...">
      <div id="search-content"></div>
    </div>
    
    <div class="section-wrap">
      <div class="container">
        <div class="columns">
          <main class="main-column">
<article class="card card-content">
  <header>
    <h1 class="post-title">
      Scrapy框架（2）
    </h1>
  </header>
  <div class="post-meta post-show-meta">
    <time datetime="2019-06-22T05:18:32.000Z" style="display: flex; align-items: center;">
      <i class="iconfont icon-calendar" style="margin-right: 2px;"></i>
      <span>2019-06-22</span>
    </time>
    
    <span class="dot"></span>
    
    <a href="/categories/爬虫/" class="post-meta-link">爬虫</a>
    
    
    
    <span class="dot"></span>
    <span>849 words</span>
    
  </div>
  
  <div class="post-meta post-show-meta" style="margin-top: -10px;">
    <div style="display: flex; align-items: center;">
      <i class="iconfont icon-biaoqian" style="margin-right: 2px; font-size: 1.15rem;"></i>
      
      
        <a href="/tags/python/" class="post-meta-link">python</a>
      
    </div>
  </div>
  
  </header>
  <div id="section" class="post-content">
    <h2 id="1-scrapy-多页爬取"><a href="#1-scrapy-多页爬取" class="headerlink" title="1.scrapy 多页爬取"></a>1.scrapy 多页爬取</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># spider编码在原基础之上, 构建其他页面的url地址, 并利用scrapy.Request发起新的请求, 请求的回调函数依然是parse:page &#x3D; 1base_url &#x3D; &#39;http:&#x2F;&#x2F;www.xiaohuar.com&#x2F;list-1-%s.html&#39;if self.page &lt; 4:    page_url &#x3D; base_url%self.page    self.page +&#x3D; 1    yield scrapy.Request(url&#x3D;page_url, callback&#x3D;self.parse)# (其他文件不用改动)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="2-scrapy爬取详情页"><a href="#2-scrapy爬取详情页" class="headerlink" title="2.scrapy爬取详情页"></a>2.scrapy爬取详情页</h2><h4 id="需求-爬取笑话的标题与详情页连接-通过详情页链接-爬取详情页笑话内容"><a href="#需求-爬取笑话的标题与详情页连接-通过详情页链接-爬取详情页笑话内容" class="headerlink" title="需求: 爬取笑话的标题与详情页连接, 通过详情页链接, 爬取详情页笑话内容"></a>需求: 爬取笑话的标题与详情页连接, 通过详情页链接, 爬取详情页笑话内容</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># item编码: 定义数据持久化的字段信息</span><br><span class="line">import scrapy</span><br><span class="line">class JokeItem(scrapy.Item):</span><br><span class="line">    # define the fields for your item here like:</span><br><span class="line">    # name &#x3D; scrapy.Field()</span><br><span class="line">    title &#x3D; scrapy.Field()</span><br><span class="line">    content &#x3D; scrapy.Field()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># spider的编码:</span><br><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">import scrapy</span><br><span class="line">from ..items import JokeItem</span><br><span class="line"></span><br><span class="line">class XhSpider(scrapy.Spider):</span><br><span class="line">    name &#x3D; &#39;xh&#39;</span><br><span class="line">    # allowed_domains &#x3D; [&#39;www.baidu.com&#39;]</span><br><span class="line">    start_urls &#x3D; [&#39;http:&#x2F;&#x2F;www.jokeji.cn&#x2F;list.htm&#39;]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        li_list &#x3D; response.xpath(&#39;&#x2F;&#x2F;div[@class&#x3D;&quot;list_title&quot;]&#x2F;ul&#x2F;li&#39;)</span><br><span class="line">        for li in li_list:</span><br><span class="line">            title &#x3D; li.xpath(&#39;.&#x2F;b&#x2F;a&#x2F;text()&#39;).extract_first()</span><br><span class="line">            link &#x3D; &#39;http:&#x2F;&#x2F;www.jokeji.cn&#39; + li.xpath(&#39;.&#x2F;b&#x2F;a&#x2F;@href&#39;).extract_first()</span><br><span class="line">            yield scrapy.Request(url&#x3D;link, callback&#x3D;self.datail_parse, meta&#x3D;&#123;&quot;title&quot;:title&#125;)</span><br><span class="line"></span><br><span class="line">    def datail_parse(self, response):</span><br><span class="line">        joke_list &#x3D; response.xpath(&#39;&#x2F;&#x2F;span[@id&#x3D;&quot;text110&quot;]&#x2F;&#x2F;text()&#39;).extract()</span><br><span class="line">        title &#x3D; response.meta[&quot;title&quot;]</span><br><span class="line">        content &#x3D; &#39;&#39;</span><br><span class="line">        for s in joke_list:</span><br><span class="line">            content +&#x3D; s</span><br><span class="line">        item &#x3D; JokeItem()</span><br><span class="line">        item[&quot;title&quot;] &#x3D; title</span><br><span class="line">        item[&quot;content&quot;] &#x3D; content</span><br><span class="line">        yield item</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Pipeline编码: 数据持久化具体操作</span><br><span class="line">import pymongo</span><br><span class="line"></span><br><span class="line">class JokePipeline(object):</span><br><span class="line">    conn &#x3D; pymongo.MongoClient(&#39;localhost&#39;, 27017)</span><br><span class="line">    db &#x3D; conn.haha</span><br><span class="line">    table &#x3D; db.hahatable</span><br><span class="line"></span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        self.table.insert(dict(item))</span><br><span class="line">        return item</span><br><span class="line"></span><br><span class="line">    def close_spider(self, spider):</span><br><span class="line">        self.conn.close()</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># settings配置编码:</span><br><span class="line">UA伪装</span><br><span class="line">Robots协议</span><br><span class="line">Item_Pipeline</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="3-scrapy发送post请求"><a href="#3-scrapy发送post请求" class="headerlink" title="3.scrapy发送post请求"></a>3.scrapy发送post请求</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class FySpider(scrapy.Spider):</span><br><span class="line">    name &#x3D; &#39;fy&#39;</span><br><span class="line">    # allowed_domains &#x3D; [&#39;www.baidu.com&#39;]</span><br><span class="line">    start_urls &#x3D; [&#39;https:&#x2F;&#x2F;fanyi.baidu.com&#x2F;sug&#39;]</span><br><span class="line">    def start_requests(self):</span><br><span class="line">        data &#x3D; &#123;</span><br><span class="line">            &#39;kw&#39;:&#39;boy&#39;</span><br><span class="line">        &#125;</span><br><span class="line">        yield scrapy.FormRequest(url&#x3D;self.start_urls[0], callback&#x3D;self.parse, formdata&#x3D;data)</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        print(~~~~)</span><br><span class="line">        print(response.text)</span><br><span class="line">        print(json.loads(response.text))</span><br><span class="line"> print(~~~~)</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="4-scrapy中间件"><a href="#4-scrapy中间件" class="headerlink" title="4.scrapy中间件"></a>4.scrapy中间件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 中间件分类:</span><br><span class="line">	- 下载中间件: DownloadMiddleware</span><br><span class="line">	- 爬虫中间件: SpiderMiddleware</span><br><span class="line"># 中间件的作用:</span><br><span class="line">	- 下载中间件: 拦截请求与响应, 篡改请求与响应</span><br><span class="line">	- 爬虫中间件: 拦截请求与响应, 拦截管道item, 篡改请求与响应, 处理item</span><br><span class="line"># 下载中间件的主要方法:</span><br><span class="line">process_request</span><br><span class="line">process_response</span><br><span class="line">process_exception</span><br></pre></td></tr></table></figure>

<h4 id="下载中间件拦截请求-使用代理ip案例"><a href="#下载中间件拦截请求-使用代理ip案例" class="headerlink" title="下载中间件拦截请求, 使用代理ip案例"></a>下载中间件拦截请求, 使用代理ip案例</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># spider编码:</span><br><span class="line">import scrapy</span><br><span class="line">class DlproxySpider(scrapy.Spider):</span><br><span class="line">    name &#x3D; &#39;dlproxy&#39;</span><br><span class="line">    # allowed_domains &#x3D; [&#39;www.baidu.com&#39;]</span><br><span class="line">    start_urls &#x3D; [&#39;https:&#x2F;&#x2F;www.baidu.com&#x2F;s?wd&#x3D;ip&#39;]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        with open(&#39;baiduproxy.html&#39;, &#39;w&#39;, encoding&#x3D;&#39;utf-8&#39;) as f:</span><br><span class="line">            f.write(response.text)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Downloadermiddleware编码:</span><br><span class="line">def process_request(self, request, spider):</span><br><span class="line">    request.meta[&#39;proxy&#39;] &#x3D; &#39;http:&#x2F;&#x2F;111.231.90.122:8888&#39;</span><br><span class="line">    return None</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="5-下载中间件实现UA池"><a href="#5-下载中间件实现UA池" class="headerlink" title="5.下载中间件实现UA池"></a>5.下载中间件实现UA池</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># spider编码:</span><br><span class="line">class DlproxySpider(scrapy.Spider):</span><br><span class="line">    name &#x3D; &#39;dlproxy&#39;</span><br><span class="line">    # allowed_domains &#x3D; [&#39;www.baidu.com&#39;]</span><br><span class="line">    start_urls &#x3D; [&#39;https:&#x2F;&#x2F;www.baidu.com&#x2F;&#39;,&#39;https:&#x2F;&#x2F;www.baidu.com&#x2F;&#39;,&#39;https:&#x2F;&#x2F;www.baidu.com&#x2F;&#39;,&#39;https:&#x2F;&#x2F;www.baidu.com&#x2F;&#39;,&#39;https:&#x2F;&#x2F;www.baidu.com&#x2F;&#39;]</span><br><span class="line">    </span><br><span class="line">    def parse(self, response):</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># 中间件的编码:</span><br><span class="line">from scrapy import signals</span><br><span class="line">from fake_useragent import UserAgent</span><br><span class="line">import random</span><br><span class="line">ua &#x3D; UserAgent()</span><br><span class="line">ua_list &#x3D; []</span><br><span class="line">for i in range(100):    </span><br><span class="line">    ua_chrome &#x3D; ua.Chrome    </span><br><span class="line">    ua_list.append(ua_chrome)    </span><br><span class="line">class ...():    </span><br><span class="line">    def process_request(self, request, spider):        </span><br><span class="line">        # request.meta[&#39;proxy&#39;] &#x3D; &#39;http:&#x2F;&#x2F;111.231.90.122:8888&#39;        </span><br><span class="line">        print(~~~~)        </span><br><span class="line">        print(self.ua_pool)        </span><br><span class="line">        print(~~~)        </span><br><span class="line">        request.headers[&#39;User-Agent&#39;] &#x3D; random.choice(self.ua_pool)        </span><br><span class="line">        return None   </span><br><span class="line">    def process_response(self, request, response, spider):      print(~~~~)        </span><br><span class="line">         print(request.headers[&quot;User-Agent&quot;])       </span><br><span class="line">         print(~~~)        </span><br><span class="line">         return response</span><br></pre></td></tr></table></figure>

  </div>
  <div>
  
  <div class="post-note note-warning copyright" style="margin-top: 42px">
    <p><span style="font-weight: bold;">作者：</span><a target="_blank" rel="nofollow noopener noreferrer" href="https://github.com/xuMr6/xumr6.github.io.git/about">Mr xu</a></p>
    <p><span style="font-weight: bold;">文章链接：</span><a target="_blank" rel="nofollow noopener noreferrer" href="https://github.com/xuMr6/xumr6.github.io.git/2019/06/22/Scrapy%E6%A1%86%E6%9E%B6%EF%BC%882%EF%BC%89/">https://github.com/xuMr6/xumr6.github.io.git/2019/06/22/Scrapy%E6%A1%86%E6%9E%B6%EF%BC%882%EF%BC%89/</a></p>
    <p><span style="font-weight: bold;">版权声明：</span>本博客所有文章除特别声明外，转载请注明出处！</p>
  </div>
  
  </div>
</article>
<div class="nav">
  
  <div class="nav-item-prev">
    <a href="/2019/07/01/Selenium &amp; PhantomJS/" class="nav-link">
      <i class="iconfont icon-left nav-prev-icon"></i>
      <div>
        <div class="nav-label">Prev</div>
        
        <div class="nav-title">Selenium &amp; PhantomJS </div>
        
      </div>
    </a>
  </div>
  
  
  <div class="nav-item-next">
    <a href="/2019/06/12/scrapy框架（1）/" class="nav-link">
      <div>
        <div class="nav-label">Next</div>
        
        <div class="nav-title">scrapy框架（1） </div>
        
      </div>
      <i class="iconfont icon-right nav-next-icon"></i>
    </a>
  </div>
  
</div>

<div class="card card-content toc-card" id="mobiletoc">
  <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>TOC</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-scrapy-%E5%A4%9A%E9%A1%B5%E7%88%AC%E5%8F%96"><span class="toc-text">1.scrapy 多页爬取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-scrapy%E7%88%AC%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5"><span class="toc-text">2.scrapy爬取详情页</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82-%E7%88%AC%E5%8F%96%E7%AC%91%E8%AF%9D%E7%9A%84%E6%A0%87%E9%A2%98%E4%B8%8E%E8%AF%A6%E6%83%85%E9%A1%B5%E8%BF%9E%E6%8E%A5-%E9%80%9A%E8%BF%87%E8%AF%A6%E6%83%85%E9%A1%B5%E9%93%BE%E6%8E%A5-%E7%88%AC%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5%E7%AC%91%E8%AF%9D%E5%86%85%E5%AE%B9"><span class="toc-text">需求: 爬取笑话的标题与详情页连接, 通过详情页链接, 爬取详情页笑话内容</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-scrapy%E5%8F%91%E9%80%81post%E8%AF%B7%E6%B1%82"><span class="toc-text">3.scrapy发送post请求</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-scrapy%E4%B8%AD%E9%97%B4%E4%BB%B6"><span class="toc-text">4.scrapy中间件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%8B%A6%E6%88%AA%E8%AF%B7%E6%B1%82-%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86ip%E6%A1%88%E4%BE%8B"><span class="toc-text">下载中间件拦截请求, 使用代理ip案例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E4%B8%8B%E8%BD%BD%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%AE%9E%E7%8E%B0UA%E6%B1%A0"><span class="toc-text">5.下载中间件实现UA池</span></a></li></ol>
</div></main>
          <aside class="left-column">
            
            <div class="card card-author">
              
<img src="/img/1.jpg" class="author-img">

<p class="author-name">Mr xu</p>
<p class="author-description"></p>
<div class="author-message">
  <a class="author-posts-count" href="/archives">
    <span>113</span>
    <span>Posts</span>
  </a>
  <a class="author-categories-count" href="/categories">
    <span>18</span>
    <span>Categories</span>
  </a>
  <a class="author-tags-count" href="/tags">
    <span>2</span>
    <span>Tags</span>
  </a>
</div>

            </div>
            
            <div class="sticky-tablet">
  
  
  <article class="display-when-two-columns spacer">
    <div class="card card-content toc-card">
      <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>TOC</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-scrapy-%E5%A4%9A%E9%A1%B5%E7%88%AC%E5%8F%96"><span class="toc-text">1.scrapy 多页爬取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-scrapy%E7%88%AC%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5"><span class="toc-text">2.scrapy爬取详情页</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82-%E7%88%AC%E5%8F%96%E7%AC%91%E8%AF%9D%E7%9A%84%E6%A0%87%E9%A2%98%E4%B8%8E%E8%AF%A6%E6%83%85%E9%A1%B5%E8%BF%9E%E6%8E%A5-%E9%80%9A%E8%BF%87%E8%AF%A6%E6%83%85%E9%A1%B5%E9%93%BE%E6%8E%A5-%E7%88%AC%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5%E7%AC%91%E8%AF%9D%E5%86%85%E5%AE%B9"><span class="toc-text">需求: 爬取笑话的标题与详情页连接, 通过详情页链接, 爬取详情页笑话内容</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-scrapy%E5%8F%91%E9%80%81post%E8%AF%B7%E6%B1%82"><span class="toc-text">3.scrapy发送post请求</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-scrapy%E4%B8%AD%E9%97%B4%E4%BB%B6"><span class="toc-text">4.scrapy中间件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%8B%A6%E6%88%AA%E8%AF%B7%E6%B1%82-%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86ip%E6%A1%88%E4%BE%8B"><span class="toc-text">下载中间件拦截请求, 使用代理ip案例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E4%B8%8B%E8%BD%BD%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%AE%9E%E7%8E%B0UA%E6%B1%A0"><span class="toc-text">5.下载中间件实现UA池</span></a></li></ol>
    </div>
  </article>
  
  
  <article class="card card-content categories-widget">
    <div class="categories-card">
  <div class="categories-header"><i class="iconfont icon-fenlei" style="padding-right: 2px;"></i>Categories</div>
  <div class="categories-list">
    
      <a href="/categories/celery">
        <div class="categories-list-item">
          celery
          <span class="categories-list-item-badge">3</span>
        </div>
      </a>
    
      <a href="/categories/docker">
        <div class="categories-list-item">
          docker
          <span class="categories-list-item-badge">4</span>
        </div>
      </a>
    
      <a href="/categories/djangobook">
        <div class="categories-list-item">
          djangobook
          <span class="categories-list-item-badge">22</span>
        </div>
      </a>
    
      <a href="/categories/django">
        <div class="categories-list-item">
          django
          <span class="categories-list-item-badge">22</span>
        </div>
      </a>
    
      <a href="/categories/ES检索">
        <div class="categories-list-item">
          ES检索
          <span class="categories-list-item-badge">2</span>
        </div>
      </a>
    
      <a href="/categories/jwt">
        <div class="categories-list-item">
          jwt
          <span class="categories-list-item-badge">2</span>
        </div>
      </a>
    
      <a href="/categories/linux">
        <div class="categories-list-item">
          linux
          <span class="categories-list-item-badge">1</span>
        </div>
      </a>
    
      <a href="/categories/python">
        <div class="categories-list-item">
          python
          <span class="categories-list-item-badge">13</span>
        </div>
      </a>
    
      <a href="/categories/mysql">
        <div class="categories-list-item">
          mysql
          <span class="categories-list-item-badge">6</span>
        </div>
      </a>
    
      <a href="/categories/nginx">
        <div class="categories-list-item">
          nginx
          <span class="categories-list-item-badge">2</span>
        </div>
      </a>
    
      <a href="/categories/支付宝扫码">
        <div class="categories-list-item">
          支付宝扫码
          <span class="categories-list-item-badge">1</span>
        </div>
      </a>
    
      <a href="/categories/redis">
        <div class="categories-list-item">
          redis
          <span class="categories-list-item-badge">3</span>
        </div>
      </a>
    
      <a href="/categories/爬虫">
        <div class="categories-list-item">
          爬虫
          <span class="categories-list-item-badge">9</span>
        </div>
      </a>
    
      <a href="/categories/vue">
        <div class="categories-list-item">
          vue
          <span class="categories-list-item-badge">8</span>
        </div>
      </a>
    
      <a href="/categories/git">
        <div class="categories-list-item">
          git
          <span class="categories-list-item-badge">1</span>
        </div>
      </a>
    
      <a href="/categories/mongodb">
        <div class="categories-list-item">
          mongodb
          <span class="categories-list-item-badge">1</span>
        </div>
      </a>
    
      <a href="/categories/编程">
        <div class="categories-list-item">
          编程
          <span class="categories-list-item-badge">1</span>
        </div>
      </a>
    
      <a href="/categories/算法">
        <div class="categories-list-item">
          算法
          <span class="categories-list-item-badge">3</span>
        </div>
      </a>
    
  </div>
</div>
  </article>
  
  <article class="card card-content tags-widget">
    <div class="tags-card">
  <div class="tags-header"><i class="iconfont icon-biaoqian" style="padding-right: 2px;"></i>hot tags</div>
  <div class="tags-list">
    
    <a href="\tags\python" title="python"><div class="tags-list-item">python</div></a>
    
    <a href="\tags\Linux" title="Linux"><div class="tags-list-item">Linux</div></a>
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
          <aside class="right-column">
            <div class="sticky-widescreen">
  
  
  <article class="card card-content toc-card">
    <div class="toc-header"><i class="iconfont icon-menu" style="padding-right: 2px;"></i>TOC</div>
<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-scrapy-%E5%A4%9A%E9%A1%B5%E7%88%AC%E5%8F%96"><span class="toc-text">1.scrapy 多页爬取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-scrapy%E7%88%AC%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5"><span class="toc-text">2.scrapy爬取详情页</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9C%80%E6%B1%82-%E7%88%AC%E5%8F%96%E7%AC%91%E8%AF%9D%E7%9A%84%E6%A0%87%E9%A2%98%E4%B8%8E%E8%AF%A6%E6%83%85%E9%A1%B5%E8%BF%9E%E6%8E%A5-%E9%80%9A%E8%BF%87%E8%AF%A6%E6%83%85%E9%A1%B5%E9%93%BE%E6%8E%A5-%E7%88%AC%E5%8F%96%E8%AF%A6%E6%83%85%E9%A1%B5%E7%AC%91%E8%AF%9D%E5%86%85%E5%AE%B9"><span class="toc-text">需求: 爬取笑话的标题与详情页连接, 通过详情页链接, 爬取详情页笑话内容</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-scrapy%E5%8F%91%E9%80%81post%E8%AF%B7%E6%B1%82"><span class="toc-text">3.scrapy发送post请求</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-scrapy%E4%B8%AD%E9%97%B4%E4%BB%B6"><span class="toc-text">4.scrapy中间件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%8B%A6%E6%88%AA%E8%AF%B7%E6%B1%82-%E4%BD%BF%E7%94%A8%E4%BB%A3%E7%90%86ip%E6%A1%88%E4%BE%8B"><span class="toc-text">下载中间件拦截请求, 使用代理ip案例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E4%B8%8B%E8%BD%BD%E4%B8%AD%E9%97%B4%E4%BB%B6%E5%AE%9E%E7%8E%B0UA%E6%B1%A0"><span class="toc-text">5.下载中间件实现UA池</span></a></li></ol>
  </article>
  
  
  <article class="card card-content">
    <div class="recent-posts-card">
  <div class="recent-posts-header"><i class="iconfont icon-wenzhang_huaban" style="padding-right: 2px;"></i>Recent Posts</div>
  <div class="recent-posts-list">
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-09-06</div>
        <a href="/2020/09/06/Python基础知识点大全/"><div class="recent-posts-item-content">Python基础知识点大全</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-08-29</div>
        <a href="/2020/08/29/Django + uWSGI + Nginx 的生产环境部署，及WSGI &amp; uwsgi &amp; uWSGI 的作用/"><div class="recent-posts-item-content">Django + uWSGI + Nginx 的生产环境部署，及WSGI &amp; uwsgi &amp; uWSGI 的作用</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-08-27</div>
        <a href="/2020/08/27/Docker 的基本常用命令/"><div class="recent-posts-item-content">Docker 的基本常用命令</div></a>
      </div>
    
      <div class="recent-posts-item">
        <div class="recent-posts-item-title">2020-08-25</div>
        <a href="/2020/08/25/Docker 镜像 &amp; 容器和镜像的联系 读写层/"><div class="recent-posts-item-content">Docker 镜像 &amp; 容器和镜像的联系 读写层</div></a>
      </div>
    
  </div>
</div>
  </article>
  
  
</div>
          </aside>
        </div>
      </div>
    </div>
  </div>
  
  <footer class="footer">
  <div class="footer-container">
    <div>
      <div class="footer-dsc">
        <span>Copyright ©
          
          2020 -
          
          2020
        </span>
        &nbsp;
        <a href="/" class="footer-link">Mr xu </a>
      </div>
    </div>

    
    <div class="footer-dsc">
      
      Powered by
      <a href="https://hexo.io/" class="footer-link" target="_blank" rel="nofollow noopener noreferrer">&nbsp;Hexo </a>
      
      
      <span>&nbsp;|&nbsp;</span>
      
      
      Theme -
      <a href="https://github.com/theme-kaze" class="footer-link" target="_blank"
        rel="nofollow noopener noreferrer">&nbsp;Kaze</a>
      
    </div>
    
    
    
    
</footer>
  <a role="button" id="scrollbutton" class="basebutton" >
  <i class="iconfont icon-arrowleft button-icon"></i>
</a>
<a role="button" id="menubutton" class="basebutton">
  <i class="iconfont icon-menu button-icon"></i>
</a>
<a role="button" id="popbutton" class="basebutton">
  <i class="iconfont icon-expand button-icon"></i>
</a>
<a role="button" id="darkbutton" class="basebutton darkwidget">
  <i class="iconfont icon-weather button-icon"></i>
</a>
<a role="button" id="searchbutton" class="basebutton searchwidget">
  <i class="iconfont icon-search button-icon"></i>
</a>

  
  
  
  <script>
  var addImgLayout = function () {
    var img = document.querySelectorAll('.post-content img');
    var i;
    for (i = 0; i < img.length; i++) {
      var wrapper = document.createElement('a');
      wrapper.setAttribute('data-fslightbox', 'gallery');
      wrapper.setAttribute('href', img[i].getAttribute('data-src'));
      wrapper.style.cssText = 'width: 100%; display: flex; justify-content: center;';
      img[i].before(wrapper);
      wrapper.append(img[i]);
    }
    refreshFsLightbox();
  }
</script>
<script>loadScript("//cdn.jsdelivr.net/npm/fslightbox@3.1.0/index.min.js", addImgLayout)</script>
  
  
  
<script src="/js/main.js"></script>

  
  
  <script>
    var addLazyload = function () {
      var observer = lozad('.lozad', {
        load: function (el) {
          el.srcset = el.getAttribute('data-src');
        },
        loaded: function (el) {
          el.classList.add('loaded');
        }
      });
      observer.observe();
    }
  </script>
  <script>loadScript("/js/lib/lozad.min.js", addLazyload)</script>
  
  
</body>

</html>